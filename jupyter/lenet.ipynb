{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq import Overlay\n",
    "from pynq import Xlnk\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image as PIL_Image\n",
    "from PIL import ImageEnhance\n",
    "from PIL import ImageOps\n",
    "from scipy import misc\n",
    "\n",
    "overlay = Overlay('my_lenet.bit')\n",
    "top = overlay.top_fun_0\n",
    "\n",
    "def top_fun(pic_in, w_in, out, bias, layer):\n",
    "    top.write(0x10,pic_in)#pic_in\n",
    "    top.write(0x18,w_in)#w\n",
    "    top.write(0x20,out)#out\n",
    "    top.write(0x28,bias)#bias\n",
    "    top.write(0x30,layer)#layer\n",
    "    top.write(0x00,0x01)#写入1 将ap_start置1 启动\n",
    "    while(top.read(0)!=0x04):#等待完成\n",
    "        a=1\n",
    "    return 0\n",
    "\n",
    "xlnk = Xlnk()\n",
    "input_pic = xlnk.cma_array(shape=(32*32,), dtype=np.float32)\n",
    "POOL24_DRAM = xlnk.cma_array(shape=(16*14*14,), dtype=np.float32)\n",
    "C5_DRAM = xlnk.cma_array(shape=(120,), dtype=np.float32)\n",
    "C6_DRAM = xlnk.cma_array(shape=(84,), dtype=np.float32)\n",
    "C7_DRAM = xlnk.cma_array(shape=(10,), dtype=np.float32)\n",
    "W_CONV1 = xlnk.cma_array(shape=(6*5*5,), dtype=np.float32)\n",
    "W_CONV3 = xlnk.cma_array(shape=(16*6*5*5,), dtype=np.float32)\n",
    "W_CONV5 = xlnk.cma_array(shape=(120*16*5*5,), dtype=np.float32)\n",
    "b_conv1 = xlnk.cma_array(shape=(6,), dtype=np.float32)\n",
    "b_conv3 = xlnk.cma_array(shape=(16,), dtype=np.float32)\n",
    "b_conv5 = xlnk.cma_array(shape=(120,), dtype=np.float32)\n",
    "WFC6 = xlnk.cma_array(shape=(10080,), dtype=np.float32)\n",
    "WFC7 = xlnk.cma_array(shape=(840,), dtype=np.float32)\n",
    "b_fc6 = xlnk.cma_array(shape=(84,), dtype=np.float32)\n",
    "b_fc7 = xlnk.cma_array(shape=(10,), dtype=np.float32)\n",
    "\n",
    "W_CONV1_buff = np.loadtxt('parameter2/conv1.0.weight.txt')\n",
    "W_CONV3_buff = np.loadtxt('parameter2/conv2.0.weight.txt')\n",
    "W_CONV5_buff = np.loadtxt('parameter2/conv3.0.weight.txt')\n",
    "\n",
    "b_conv1_buff = np.loadtxt('parameter2/conv1.0.bias.txt')\n",
    "b_conv3_buff = np.loadtxt('parameter2/conv2.0.bias.txt')\n",
    "b_conv5_buff = np.loadtxt('parameter2/conv3.0.bias.txt')\n",
    "\n",
    "WFC6_buff = np.loadtxt('parameter2/fc2.0.weight.txt')\n",
    "WFC7_buff = np.loadtxt('parameter2/fc3.weight.txt')\n",
    "\n",
    "b_fc6_buff = np.loadtxt('parameter2/fc2.0.bias.txt') \n",
    "b_fc7_buff = np.loadtxt('parameter2/fc3.bias.txt')\n",
    "for i in range(6*5*5):\n",
    "        W_CONV1[i] = W_CONV1_buff[i]\n",
    "for i in range(16*6*5*5):\n",
    "        W_CONV3[i] = W_CONV3_buff[i]\n",
    "for i in range(120*16*5*5):\n",
    "        W_CONV5[i] = W_CONV5_buff[i]\n",
    "        \n",
    "for i in range(6):\n",
    "        b_conv1[i] = b_conv1_buff[i]\n",
    "for i in range(16):\n",
    "        b_conv3[i] = b_conv3_buff[i]        \n",
    "for i in range(120):\n",
    "        b_conv5[i] = b_conv5_buff[i]          \n",
    "        \n",
    "for i in range(10080):\n",
    "        WFC6[i] = WFC6_buff[i]    \n",
    "for i in range(840):\n",
    "        WFC7[i] = WFC7_buff[i]              \n",
    "        \n",
    "for i in range(84):\n",
    "        b_fc6[i] = b_fc6_buff[i]     \n",
    "for i in range(10):\n",
    "        b_fc7[i] = b_fc7_buff[i]     \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "识别结果： T-Shirt\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACX0lEQVR4nF2OvWsUURTFz33z3szOvNlsvnYxBlERRbQRRdBOVLAQtVMQVBQb/wttJJWVrZ2gYKWNhVUUJIhfSVBBjRpCyCbZNXF3dmbnzZt3LfxAc8vz43fOJYB04puoKPZNPJ505YFjC3e++pQHJuijCqCCsa23Z2Y7q8wFT7902a09ESKAgMYKxm8eWdr5pS0HQl6L5brenLw8H6VEYZ8xeHdvalq1Wtp2QVgqvyN0dGEKUmYqMlt3L3d1va5DH0VvsLdGJekLU56TupcWpyId5wM35mghziga3nttKRs8AdUnVQAzXlYGbv/JoYenV8L02+c5dtmW428dEMO37z69+zAdLpcTfL/DL9Tcs/lXi5cgRJDgcHNNizhzR7c/ia42hq4X7eFvA/NnAJk39FlXnx/KeoeiYDSqJP36OaU3vT/4vNqVWMHsrqOLW56OP6r46zIuFJYXFhvbHrwoQPCUtbUdly9+jL6OmFBa6fKRN1eyTSuOhF+SxY+Ze0urZrg6Tt0kDLJyOlNN5wtpQKEL0pZpVP1mzdRdkNSjuWo3zBwLgTTLu7adm/kkrMnENhPufQ+8DFYIQoCIVXs90AF1rAp4TIWDLYkYQpTIkaJA9N24iqiyU2kn/AGHBEbi92mSqmRXAmD3OxV/oKeUAIOZiMvKr+yvaSzZkoRgEs5G4P9M6+BKEh4TcaF/wb+mJxSIBIHIWb1hkzyPQIKYiMtgQ23pnGMSAiCw2mC2dOGxM1JKLp3e8K0tjGQ2lAkfYLj/YFWLEdLM2tqmigPq/wsnR1tx4WUmZ9ix1zkA4CfMNibIEue5nwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0xA418E8F0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_map = {\n",
    "    0: \"Bag\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"T-Shirt\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "img_load = PIL_Image.open('vali_data2/1.jpg').convert(\"L\") \n",
    "img_load = img_load.resize((28, 28),PIL_Image.ANTIALIAS)\n",
    "\n",
    "img_numpy = np.asarray(img_load)\n",
    "\n",
    "img_numpy= np.pad(img_numpy, ((2, 2), (2, 2)), 'constant', constant_values=(255, 255))\n",
    "input_pic.physical_address \n",
    "for i in range(32):\n",
    "    for j in range(32):\n",
    "        input_pic[i*32+j] = 1 - float(img_numpy[i][j]) / 255.0;  \n",
    "        \n",
    "        \n",
    "top_fun( input_pic.physical_address, W_CONV1.physical_address, POOL24_DRAM.physical_address, b_conv1.physical_address, 1)\n",
    "top_fun( POOL24_DRAM.physical_address, W_CONV3.physical_address, POOL24_DRAM.physical_address, b_conv3.physical_address, 2)\n",
    "top_fun( POOL24_DRAM.physical_address, W_CONV5.physical_address, C5_DRAM.physical_address, b_conv5.physical_address, 3)\n",
    "top_fun( C5_DRAM.physical_address, WFC6.physical_address, C6_DRAM.physical_address, b_fc6.physical_address, 4)\n",
    "top_fun( C6_DRAM.physical_address, WFC7.physical_address, C7_DRAM.physical_address, b_fc7.physical_address, 5)\n",
    "\n",
    "\n",
    "max=0\n",
    "max_locotion=0\n",
    "for i in range(10):\n",
    "    if(C7_DRAM[i]>max):\n",
    "        max = C7_DRAM[i]\n",
    "        max_locotion=i\n",
    "\n",
    "\n",
    "res = labels_map[max_locotion]\n",
    "print(\"识别结果：\", res)\n",
    "img_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
